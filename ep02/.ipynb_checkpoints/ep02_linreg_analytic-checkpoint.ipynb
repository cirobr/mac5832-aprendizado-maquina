{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name:  Ciro B Rosa / No USP 2320769\n",
      "\n",
      "Honor pledge:  I affirm that I have not given or received any unauthorized help on this assignment, and that this work is my own.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "name = \"Ciro B Rosa / No USP 2320769\"  # write YOUR NAME\n",
    "\n",
    "honorPledge = \"I affirm that I have not given or received any unauthorized \" \\\n",
    "              \"help on this assignment, and that this work is my own.\\n\"\n",
    "\n",
    "\n",
    "print(\"\\nName: \", name)\n",
    "print(\"\\nHonor pledge: \", honorPledge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAC0460 / MAC5832 (2021)\n",
    "<hr>\n",
    "\n",
    "# EP2: Linear regression - analytic solution\n",
    "\n",
    "### Objectives:\n",
    "\n",
    "- to implement and test the analytic solution for the linear regression task (see, for instance, <a href=\"http://work.caltech.edu/slides/slides03.pdf\">Slides of Lecture 03</a> and Lecture 03 of *Learning from Data*)\n",
    "- to understand the core idea (*optimization of a loss or cost function*) for parameter adjustment in machine learning\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression\n",
    "\n",
    "Given a dataset $\\{(\\mathbf{x}^{(1)}, y^{(1)}), \\dots ,(\\mathbf{x}^{(N)}, y^{(N)})\\}$ with $\\mathbf{x}^{(i)} \\in \\mathbb{R}^{d}$ and $y^{(i)} \\in \\mathbb{R}$, we would like to approximate the unknown function $f:\\mathbb{R}^{d} \\rightarrow \\mathbb{R}$ (recall that $y^{(i)} =f(\\mathbf{x}^{(i)})$) by means of a linear model $h$:\n",
    "$$\n",
    "h(\\mathbf{x}^{(i)}; \\mathbf{w}, b) = \\mathbf{w}^\\top  \\mathbf{x}^{(i)} + b\n",
    "$$\n",
    "\n",
    "Note that $h(\\mathbf{x}^{(i)}; \\mathbf{w}, b)$ is, in fact, an  [affine transformation](https://en.wikipedia.org/wiki/Affine_transformation) of  $\\mathbf{x}^{(i)}$. As commonly done, we will use the term \"linear\" to refer to an affine transformation.\n",
    "\n",
    "The output of $h$ is a linear transformation of $\\mathbf{x}^{(i)}$. We use the notation $h(\\mathbf{x}^{(i)}; \\mathbf{w}, b)$ to make clear that $h$ is a parametric model, i.e., the transformation $h$ is defined  by the parameters $\\mathbf{w}$ and $b$. We can view vector $\\mathbf{w}$ as a *weight* vector that controls the effect of each *feature* in the prediction.\n",
    "\n",
    "By adding one component with value equal to 1 to the observations $\\mathbf{x}$ (an artificial coordinate), we have:\n",
    "\n",
    "$$\\tilde{\\mathbf{x}} = (1, x_1, \\ldots, x_d) \\in \\mathbb{R}^{1+d}$$\n",
    "\n",
    "and then we can simplify the notation:\n",
    "$$\n",
    "h(\\mathbf{x}^{(i)}; \\mathbf{w}) = \\hat{y}^{(i)} = \\mathbf{w}^\\top  \\tilde{\\mathbf{x}}^{(i)}\n",
    "$$\n",
    "\n",
    "We would like to determine the optimal parameters $\\mathbf{w}$ such that prediction $\\hat{y}^{(i)}$ is as closest as possible to $y^{(i)}$ according to some error metric. Adopting the *mean square error* as such metric we have the following cost function:\n",
    "\n",
    "\\begin{equation}\n",
    "J(\\mathbf{w}) = \\frac{1}{N}\\sum_{i=1}^{N}\\big(\\hat{y}^{(i)} - y^{(i)}\\big)^{2}\n",
    "\\end{equation}\n",
    "\n",
    "Thus, the task of determining a function $h$ that is closest to $f$ is reduced to the task of finding the values $\\mathbf{w}$ that minimize $J(\\mathbf{w})$.\n",
    "\n",
    "**Now we will explore this model, starting with a simple dataset.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some imports\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An auxiliary function\n",
    "def get_housing_prices_data(N, verbose=True):\n",
    "    \"\"\"\n",
    "    Generates artificial linear data,\n",
    "    where x = square meter, y = house price\n",
    "\n",
    "    :param N: data set size\n",
    "    :type N: int\n",
    "    \n",
    "    :param verbose: param to control print\n",
    "    :type verbose: bool\n",
    "    :return: design matrix, regression targets\n",
    "    :rtype: np.array, np.array\n",
    "    \"\"\"\n",
    "    cond = False\n",
    "    while not cond:\n",
    "        x = np.linspace(90, 1200, N)\n",
    "        gamma = np.random.normal(30, 10, x.size)\n",
    "        y = 50 * x + gamma * 400\n",
    "        x = x.astype(\"float32\")\n",
    "        x = x.reshape((x.shape[0], 1))\n",
    "        y = y.astype(\"float32\")\n",
    "        y = y.reshape((y.shape[0], 1))\n",
    "        cond = min(y) > 0\n",
    "        \n",
    "    xmean, xsdt, xmax, xmin = np.mean(x), np.std(x), np.max(x), np.min(x)\n",
    "    ymean, ysdt, ymax, ymin = np.mean(y), np.std(y), np.max(y), np.min(y)\n",
    "    if verbose:\n",
    "        print(\"\\nX shape = {}\".format(x.shape))\n",
    "        print(\"y shape = {}\\n\".format(y.shape))\n",
    "        print(\"X: mean {}, sdt {:.2f}, max {:.2f}, min {:.2f}\".format(xmean,\n",
    "                                                               xsdt,\n",
    "                                                               xmax,\n",
    "                                                               xmin))\n",
    "        print(\"y: mean {:.2f}, sdt {:.2f}, max {:.2f}, min {:.2f}\".format(ymean,\n",
    "                                                                 ysdt,\n",
    "                                                                 ymax,\n",
    "                                                                 ymin))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another auxiliary function\n",
    "def plot_points_regression(x,\n",
    "                           y,\n",
    "                           title,\n",
    "                           xlabel,\n",
    "                           ylabel,\n",
    "                           prediction=None,\n",
    "                           legend=False,\n",
    "                           r_squared=None,\n",
    "                           position=(90, 100)):\n",
    "    \"\"\"\n",
    "    Plots the data points and the prediction,\n",
    "    if there is one.\n",
    "\n",
    "    :param x: design matrix\n",
    "    :type x: np.array\n",
    "    :param y: regression targets\n",
    "    :type y: np.array\n",
    "    :param title: plot's title\n",
    "    :type title: str\n",
    "    :param xlabel: x axis label\n",
    "    :type xlabel: str\n",
    "    :param ylabel: y axis label\n",
    "    :type ylabel: str\n",
    "    :param prediction: model's prediction\n",
    "    :type prediction: np.array\n",
    "    :param legend: param to control print legends\n",
    "    :type legend: bool\n",
    "    :param r_squared: r^2 value\n",
    "    :type r_squared: float\n",
    "    :param position: text position\n",
    "    :type position: tuple\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "    line1, = ax.plot(x, y, 'bo', label='Real data')\n",
    "    if prediction is not None:\n",
    "        line2, = ax.plot(x, prediction, 'r', label='Predicted data')\n",
    "        if legend:\n",
    "            plt.legend(handles=[line1, line2], loc=2)\n",
    "        ax.set_title(title,\n",
    "                 fontsize=20,\n",
    "                 fontweight='bold')\n",
    "    if r_squared is not None:\n",
    "        bbox_props = dict(boxstyle=\"square,pad=0.3\",\n",
    "                          fc=\"white\", ec=\"black\", lw=0.2)\n",
    "        t = ax.text(position[0], position[1], \"$R^2 ={:.4f}$\".format(r_squared),\n",
    "                    size=15, bbox=bbox_props)\n",
    "\n",
    "    ax.set_xlabel(xlabel, fontsize=20)\n",
    "    ax.set_ylabel(ylabel, fontsize=20)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset \n",
    "\n",
    "The first dataset we will use is a toy dataset. We will generate $N=100$ observations with only one *feature* and a real value associated to each of them. We can view these observations as being pairs *(area of a real state in square meters, price of the real state)*. Our task is to construct a model that is able to predict the price of a real state, given its area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X shape = (100, 1)\n",
      "y shape = (100, 1)\n",
      "\n",
      "X: mean 645.0, sdt 323.65, max 1200.00, min 90.00\n",
      "y: mean 44313.73, sdt 15771.95, max 76337.54, min 12784.78\n"
     ]
    }
   ],
   "source": [
    "X, y = get_housing_prices_data(N=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_points_regression(X,\n",
    "                       y,\n",
    "                       title='Real estate prices prediction',\n",
    "                       xlabel=\"m\\u00b2\",\n",
    "                       ylabel='$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The solution\n",
    "\n",
    "Given $f:\\mathbb{R}^{N\\times M} \\rightarrow \\mathbb{R}$ and $\\mathbf{A} \\in \\mathbb{R}^{N\\times M}$, we define the gradient of $f$ with respect to $\\mathbf{A}$ as:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\nabla_{\\mathbf{A}}f = \\frac{\\partial f}{\\partial \\mathbf{A}} =  \\begin{bmatrix}\n",
    "\\frac{\\partial f}{\\partial \\mathbf{A}_{1,1}} & \\dots & \\frac{\\partial f}{\\partial \\mathbf{A}_{1,m}} \\\\\n",
    "\\vdots &  \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial f}{\\partial \\mathbf{A}_{n,1}} &  \\dots & \\frac{\\partial f}{\\partial \\mathbf{A}_{n,m}}\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Let $\\mathbf{X} \\in \\mathbb{R}^{N\\times d}$ be a matrix (sometimes also called the *design matrix*) whose rows are the observations of the dataset and let $\\mathbf{y} \\in \\mathbb{R}^{N}$ be the vector consisting of all values $y^{(i)}$ (i.e., $\\mathbf{X}^{(i,:)} = \\mathbf{x}^{(i)}$ and $\\mathbf{y}^{(i)} = y^{(i)}$). It can be verified that: \n",
    "\n",
    "\\begin{equation}\n",
    "J(\\mathbf{w}) = \\frac{1}{N}(\\mathbf{X}\\mathbf{w} - \\mathbf{y})^{T}(\\mathbf{X}\\mathbf{w} - \\mathbf{y})\n",
    "\\end{equation}\n",
    "\n",
    "Using basic matrix derivative concepts we can compute the gradient of $J(\\mathbf{w})$ with respect to $\\mathbf{w}$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_{\\mathbf{w}}J(\\mathbf{w}) = \\frac{2}{N} (\\mathbf{X}^{T}\\mathbf{X}\\mathbf{w} -\\mathbf{X}^{T}\\mathbf{y})   \n",
    "\\end{equation}\n",
    "\n",
    "Thus, when $\\nabla_{\\mathbf{w}}J(\\mathbf{w}) = 0$ we have \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{X}^{T}\\mathbf{X}\\mathbf{w} = \\mathbf{X}^{T}\\mathbf{y}\n",
    "\\end{equation}\n",
    "\n",
    "Hence,\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{w} = (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\mathbf{y}\n",
    "\\end{equation}\n",
    "\n",
    "Note that this solution has a high computational cost. As the number of variables (*features*) increases, the cost for matrix inversion becomes prohibitive. See  [this text](https://sgfin.github.io/files/notes/CS229_Lecture_Notes.pdf) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <mark>Exercise 1</mark>\n",
    "Using only **NumPy** (a quick introduction to this library can be found  [here](http://cs231n.github.io/python-numpy-tutorial/)), complete the two functions below. Recall that $\\mathbf{X} \\in \\mathbb{R}^{N\\times d}$; thus you will need to add a component of value 1 to each of  the observations in $\\mathbf{X}$ before performing the computation described above.\n",
    "\n",
    "NOTE: Although the dataset above has data of dimension $d=1$, your code must be generic (it should work for $d\\geq1$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>1.1. Weight computation function</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation_weights(X, y):\n",
    "    \"\"\"\n",
    "    Calculates the weights of a linear function using the normal equation method.\n",
    "    You should add into X a new column with 1s.\n",
    "\n",
    "    :param X: design matrix\n",
    "    :type X: np.ndarray(shape=(N, d))\n",
    "    :param y: regression targets\n",
    "    :type y: np.ndarray(shape=(N, 1))\n",
    "    :return: weight vector\n",
    "    :rtype: np.ndarray(shape=(d+1, 1))\n",
    "    \"\"\"\n",
    "    \n",
    "    # START OF YOUR CODE:\n",
    "    #raise NotImplementedError(\"Function normal_equation_weights() is not implemented\")\n",
    "    import numpy as np\n",
    "    from numpy.linalg import inv\n",
    "    Xt = X.T\n",
    "    X1 = inv(np.dot(Xt, X))\n",
    "    X2 = np.dot(X1, Xt)\n",
    "    w = np.dot(X2, y)\n",
    "    return(y)\n",
    "    \n",
    "    # END OF YOUR CODE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated w =\n",
      " [[19691.256]\n",
      " [15188.76 ]\n",
      " [14743.208]\n",
      " [12784.78 ]\n",
      " [23653.398]\n",
      " [23553.479]\n",
      " [17476.67 ]\n",
      " [23953.172]\n",
      " [22956.398]\n",
      " [17473.523]\n",
      " [23832.459]\n",
      " [26486.871]\n",
      " [25548.508]\n",
      " [26664.615]\n",
      " [27067.113]\n",
      " [18414.705]\n",
      " [25438.906]\n",
      " [26868.748]\n",
      " [31091.57 ]\n",
      " [28543.135]\n",
      " [35578.113]\n",
      " [28805.238]\n",
      " [28090.781]\n",
      " [36953.355]\n",
      " [34594.652]\n",
      " [27707.477]\n",
      " [27156.725]\n",
      " [35907.242]\n",
      " [37007.984]\n",
      " [31360.531]\n",
      " [35935.273]\n",
      " [40980.703]\n",
      " [38391.23 ]\n",
      " [41499.08 ]\n",
      " [32723.627]\n",
      " [40305.98 ]\n",
      " [31306.746]\n",
      " [32337.814]\n",
      " [43070.133]\n",
      " [36408.805]\n",
      " [42082.688]\n",
      " [35901.312]\n",
      " [44678.566]\n",
      " [41488.707]\n",
      " [32460.705]\n",
      " [41357.707]\n",
      " [42476.04 ]\n",
      " [44773.21 ]\n",
      " [43481.82 ]\n",
      " [44158.51 ]\n",
      " [45315.562]\n",
      " [44607.08 ]\n",
      " [46456.312]\n",
      " [36203.355]\n",
      " [43923.227]\n",
      " [47734.074]\n",
      " [51908.605]\n",
      " [48153.047]\n",
      " [53805.43 ]\n",
      " [52839.617]\n",
      " [53445.85 ]\n",
      " [51566.29 ]\n",
      " [47418.062]\n",
      " [49308.01 ]\n",
      " [49521.11 ]\n",
      " [47361.555]\n",
      " [48795.727]\n",
      " [57431.19 ]\n",
      " [53336.08 ]\n",
      " [56780.324]\n",
      " [57175.516]\n",
      " [50347.88 ]\n",
      " [51090.08 ]\n",
      " [62838.277]\n",
      " [51295.094]\n",
      " [60350.914]\n",
      " [59466.04 ]\n",
      " [61887.85 ]\n",
      " [58405.926]\n",
      " [56877.395]\n",
      " [59194.2  ]\n",
      " [58307.52 ]\n",
      " [58449.74 ]\n",
      " [65010.074]\n",
      " [63175.246]\n",
      " [63992.414]\n",
      " [63970.39 ]\n",
      " [63059.24 ]\n",
      " [61789.15 ]\n",
      " [62370.58 ]\n",
      " [68570.195]\n",
      " [70658.164]\n",
      " [66883.74 ]\n",
      " [76337.54 ]\n",
      " [64651.062]\n",
      " [72288.85 ]\n",
      " [71285.33 ]\n",
      " [74726.89 ]\n",
      " [64964.01 ]\n",
      " [65631.67 ]]\n"
     ]
    }
   ],
   "source": [
    "# test of function normal_equation_weights()\n",
    "\n",
    "w = 0  # this is not necessary\n",
    "w = normal_equation_weights(X, y)\n",
    "print(\"Estimated w =\\n\", w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>1.2. Prediction function</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation_prediction(X, w):\n",
    "    \"\"\"\n",
    "    Calculates the prediction over a set of observations X using the linear function\n",
    "    characterized by the weight vector w.\n",
    "    You should add into X a new column with 1s.\n",
    "\n",
    "    :param X: design matrix\n",
    "    :type X: np.ndarray(shape=(N, d))\n",
    "    :param w: weight vector\n",
    "    :type w: np.ndarray(shape=(d+1, 1))\n",
    "    :param y: regression prediction\n",
    "    :type y: np.ndarray(shape=(N, 1))\n",
    "    \"\"\"\n",
    "    \n",
    "    # START OF YOUR CODE:\n",
    "    raise NotImplementedError(\"Function normal_equation_prediction() is not implemented\")\n",
    "    # END OF YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>1.3. Coefficient of determination</mark>\n",
    "We can use the [$R^2$](https://pt.wikipedia.org/wiki/R%C2%B2) metric (Coefficient of determination) to evaluate how well the linear model fits the data.\n",
    "\n",
    "**Which $𝑅^2$ value would you expect to observe ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# test of function normal_equation_prediction()\n",
    "prediction = normal_equation_prediction(X, w)\n",
    "\n",
    "# compute the R2 score using the r2_score function from sklearn\n",
    "# Replace 0 with an appropriate call of the function\n",
    "\n",
    "# START OF YOUR CODE:\n",
    "r_2 = 0\n",
    "# END OF YOUR CODE\n",
    "\n",
    "plot_points_regression(X,\n",
    "                       y,\n",
    "                       title='Real estate prices prediction',\n",
    "                       xlabel=\"m\\u00b2\",\n",
    "                       ylabel='$',\n",
    "                       prediction=prediction,\n",
    "                       legend=True,\n",
    "                       r_squared=r_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional tests\n",
    "\n",
    "Let us compute a prediction for $x=650$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us use the prediction function\n",
    "x = np.asarray([650]).reshape(1,1)\n",
    "prediction = normal_equation_prediction(x, w)\n",
    "print(\"Area = %.2f  Predicted price = %.4f\" %(x[0], prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>1.4. Processing time</mark>\n",
    "\n",
    "Experiment with different nummber of samples $N$ and observe how processing time varies.\n",
    "\n",
    "Be careful not to use a too large value; it may make jupyter freeze ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add other values for N\n",
    "# START OF YOUR CODE:\n",
    "N = [100] \n",
    "# END OF YOUR CODE\n",
    "\n",
    "for i in N:\n",
    "    X, y = get_housing_prices_data(N=i)\n",
    "    init = time.time()\n",
    "    w = normal_equation_weights(X, y)\n",
    "    prediction = normal_equation_prediction(X,w)\n",
    "    init = time.time() - init\n",
    "    \n",
    "    print(\"\\nExecution time = {:.8f}(s)\\n\".format(init))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <mark>Exercise 2</mark>\n",
    "\n",
    "Let us test the code with $𝑑>1$. \n",
    "We will use the data we have collected in our first class. The [file](https://edisciplinas.usp.br/pluginfile.php/5982803/course/section/6115454/QT1data.csv) can be found on e-disciplinas. \n",
    "\n",
    "Let us try to predict the weight based on one or more features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the dataset\n",
    "df = pd.read_csv('QT1data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our target variable is the weight\n",
    "y = df.pop('Weight').values\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>2.1. One feature ($d=1$)</mark>\n",
    "\n",
    "We will use 'Height' as the input feature and predict the weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['Height']\n",
    "X = df.loc[:, feature_cols]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the code for computing the following\n",
    "- compute the regression weights using $\\mathbf{X}$ and $\\mathbf{y}$\n",
    "- compute the prediction\n",
    "- compute the $R^2$ value\n",
    "- plot the regression graph (use appropriate values for the parameters of function <tt>plot_points_regression()</tt>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START OF YOUR CODE:\n",
    "\n",
    "# END OF YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>2.2 - Two input features ($d=2$)</mark>\n",
    "\n",
    "Now repeat the exercise with using as input the features 'Height' and 'Shoe number'\n",
    "\n",
    "- compute the regression weights using $\\mathbf{X}$ and $\\mathbf{y}$\n",
    "- compute the prediction\n",
    "- compute and print the $R^2$ value\n",
    "\n",
    "Note that our plotting function can not be used. There is no need to do plotting here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START OF YOUR CODE:\n",
    "\n",
    "# END OF YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - <mark>Three input features ($d=3$)</mark>\n",
    "\n",
    "Now try with three features. There is no need to do plotting here.\n",
    "- compute the regression weights using $\\mathbf{X}$ and $\\mathbf{y}$\n",
    "- compute the prediction\n",
    "- compute and print the $R^2$ value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START OF YOUR CODE:\n",
    "\n",
    "# END OF YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>2.4 - Your comments</mark>\n",
    "\n",
    "Did you observe anything interesting with varying values of $d$ ? Comment about it.\n",
    "\n",
    "YOUR COMMENT BELOW:\n",
    "\n",
    "===>\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
