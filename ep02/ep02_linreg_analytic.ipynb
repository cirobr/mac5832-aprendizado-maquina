{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name:  Ciro B Rosa / No USP 2320769\n",
      "\n",
      "Honor pledge:  I affirm that I have not given or received any unauthorized help on this assignment, and that this work is my own.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "name = \"Ciro B Rosa / No USP 2320769\"  # write YOUR NAME\n",
    "\n",
    "honorPledge = \"I affirm that I have not given or received any unauthorized \" \\\n",
    "              \"help on this assignment, and that this work is my own.\\n\"\n",
    "\n",
    "\n",
    "print(\"\\nName: \", name)\n",
    "print(\"\\nHonor pledge: \", honorPledge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAC0460 / MAC5832 (2021)\n",
    "<hr>\n",
    "\n",
    "# EP2: Linear regression - analytic solution\n",
    "\n",
    "### Objectives:\n",
    "\n",
    "- to implement and test the analytic solution for the linear regression task (see, for instance, <a href=\"http://work.caltech.edu/slides/slides03.pdf\">Slides of Lecture 03</a> and Lecture 03 of *Learning from Data*)\n",
    "- to understand the core idea (*optimization of a loss or cost function*) for parameter adjustment in machine learning\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression\n",
    "\n",
    "Given a dataset $\\{(\\mathbf{x}^{(1)}, y^{(1)}), \\dots ,(\\mathbf{x}^{(N)}, y^{(N)})\\}$ with $\\mathbf{x}^{(i)} \\in \\mathbb{R}^{d}$ and $y^{(i)} \\in \\mathbb{R}$, we would like to approximate the unknown function $f:\\mathbb{R}^{d} \\rightarrow \\mathbb{R}$ (recall that $y^{(i)} =f(\\mathbf{x}^{(i)})$) by means of a linear model $h$:\n",
    "$$\n",
    "h(\\mathbf{x}^{(i)}; \\mathbf{w}, b) = \\mathbf{w}^\\top  \\mathbf{x}^{(i)} + b\n",
    "$$\n",
    "\n",
    "Note that $h(\\mathbf{x}^{(i)}; \\mathbf{w}, b)$ is, in fact, an  [affine transformation](https://en.wikipedia.org/wiki/Affine_transformation) of  $\\mathbf{x}^{(i)}$. As commonly done, we will use the term \"linear\" to refer to an affine transformation.\n",
    "\n",
    "The output of $h$ is a linear transformation of $\\mathbf{x}^{(i)}$. We use the notation $h(\\mathbf{x}^{(i)}; \\mathbf{w}, b)$ to make clear that $h$ is a parametric model, i.e., the transformation $h$ is defined  by the parameters $\\mathbf{w}$ and $b$. We can view vector $\\mathbf{w}$ as a *weight* vector that controls the effect of each *feature* in the prediction.\n",
    "\n",
    "By adding one component with value equal to 1 to the observations $\\mathbf{x}$ (an artificial coordinate), we have:\n",
    "\n",
    "$$\\tilde{\\mathbf{x}} = (1, x_1, \\ldots, x_d) \\in \\mathbb{R}^{1+d}$$\n",
    "\n",
    "and then we can simplify the notation:\n",
    "$$\n",
    "h(\\mathbf{x}^{(i)}; \\mathbf{w}) = \\hat{y}^{(i)} = \\mathbf{w}^\\top  \\tilde{\\mathbf{x}}^{(i)}\n",
    "$$\n",
    "\n",
    "We would like to determine the optimal parameters $\\mathbf{w}$ such that prediction $\\hat{y}^{(i)}$ is as closest as possible to $y^{(i)}$ according to some error metric. Adopting the *mean square error* as such metric we have the following cost function:\n",
    "\n",
    "\\begin{equation}\n",
    "J(\\mathbf{w}) = \\frac{1}{N}\\sum_{i=1}^{N}\\big(\\hat{y}^{(i)} - y^{(i)}\\big)^{2}\n",
    "\\end{equation}\n",
    "\n",
    "Thus, the task of determining a function $h$ that is closest to $f$ is reduced to the task of finding the values $\\mathbf{w}$ that minimize $J(\\mathbf{w})$.\n",
    "\n",
    "**Now we will explore this model, starting with a simple dataset.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some imports\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An auxiliary function\n",
    "def get_housing_prices_data(N, verbose=True):\n",
    "    \"\"\"\n",
    "    Generates artificial linear data,\n",
    "    where x = square meter, y = house price\n",
    "\n",
    "    :param N: data set size\n",
    "    :type N: int\n",
    "    \n",
    "    :param verbose: param to control print\n",
    "    :type verbose: bool\n",
    "    :return: design matrix, regression targets\n",
    "    :rtype: np.array, np.array\n",
    "    \"\"\"\n",
    "    cond = False\n",
    "    while not cond:\n",
    "        x = np.linspace(90, 1200, N)\n",
    "        gamma = np.random.normal(30, 10, x.size)\n",
    "        y = 50 * x + gamma * 400\n",
    "        x = x.astype(\"float32\")\n",
    "        x = x.reshape((x.shape[0], 1))\n",
    "        y = y.astype(\"float32\")\n",
    "        y = y.reshape((y.shape[0], 1))\n",
    "        cond = min(y) > 0\n",
    "        \n",
    "    xmean, xsdt, xmax, xmin = np.mean(x), np.std(x), np.max(x), np.min(x)\n",
    "    ymean, ysdt, ymax, ymin = np.mean(y), np.std(y), np.max(y), np.min(y)\n",
    "    if verbose:\n",
    "        print(\"\\nX shape = {}\".format(x.shape))\n",
    "        print(\"y shape = {}\\n\".format(y.shape))\n",
    "        print(\"X: mean {}, sdt {:.2f}, max {:.2f}, min {:.2f}\".format(xmean,\n",
    "                                                               xsdt,\n",
    "                                                               xmax,\n",
    "                                                               xmin))\n",
    "        print(\"y: mean {:.2f}, sdt {:.2f}, max {:.2f}, min {:.2f}\".format(ymean,\n",
    "                                                                 ysdt,\n",
    "                                                                 ymax,\n",
    "                                                                 ymin))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another auxiliary function\n",
    "def plot_points_regression(x,\n",
    "                           y,\n",
    "                           title,\n",
    "                           xlabel,\n",
    "                           ylabel,\n",
    "                           prediction=None,\n",
    "                           legend=False,\n",
    "                           r_squared=None,\n",
    "                           position=(90, 100)):\n",
    "    \"\"\"\n",
    "    Plots the data points and the prediction,\n",
    "    if there is one.\n",
    "\n",
    "    :param x: design matrix\n",
    "    :type x: np.array\n",
    "    :param y: regression targets\n",
    "    :type y: np.array\n",
    "    :param title: plot's title\n",
    "    :type title: str\n",
    "    :param xlabel: x axis label\n",
    "    :type xlabel: str\n",
    "    :param ylabel: y axis label\n",
    "    :type ylabel: str\n",
    "    :param prediction: model's prediction\n",
    "    :type prediction: np.array\n",
    "    :param legend: param to control print legends\n",
    "    :type legend: bool\n",
    "    :param r_squared: r^2 value\n",
    "    :type r_squared: float\n",
    "    :param position: text position\n",
    "    :type position: tuple\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "    line1, = ax.plot(x, y, 'bo', label='Real data')\n",
    "    if prediction is not None:\n",
    "        line2, = ax.plot(x, prediction, 'r', label='Predicted data')\n",
    "        if legend:\n",
    "            plt.legend(handles=[line1, line2], loc=2)\n",
    "        ax.set_title(title,\n",
    "                 fontsize=20,\n",
    "                 fontweight='bold')\n",
    "    if r_squared is not None:\n",
    "        bbox_props = dict(boxstyle=\"square,pad=0.3\",\n",
    "                          fc=\"white\", ec=\"black\", lw=0.2)\n",
    "        t = ax.text(position[0], position[1], \"$R^2 ={:.4f}$\".format(r_squared),\n",
    "                    size=15, bbox=bbox_props)\n",
    "\n",
    "    ax.set_xlabel(xlabel, fontsize=20)\n",
    "    ax.set_ylabel(ylabel, fontsize=20)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset \n",
    "\n",
    "The first dataset we will use is a toy dataset. We will generate $N=100$ observations with only one *feature* and a real value associated to each of them. We can view these observations as being pairs *(area of a real state in square meters, price of the real state)*. Our task is to construct a model that is able to predict the price of a real state, given its area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X shape = (100, 1)\n",
      "y shape = (100, 1)\n",
      "\n",
      "X: mean 645.0, sdt 323.65, max 1200.00, min 90.00\n",
      "y: mean 44213.68, sdt 16051.55, max 75167.76, min 13924.68\n"
     ]
    }
   ],
   "source": [
    "X, y = get_housing_prices_data(N=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_points_regression(X,\n",
    "                       y,\n",
    "                       title='Real estate prices prediction',\n",
    "                       xlabel=\"m\\u00b2\",\n",
    "                       ylabel='$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The solution\n",
    "\n",
    "Given $f:\\mathbb{R}^{N\\times M} \\rightarrow \\mathbb{R}$ and $\\mathbf{A} \\in \\mathbb{R}^{N\\times M}$, we define the gradient of $f$ with respect to $\\mathbf{A}$ as:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\nabla_{\\mathbf{A}}f = \\frac{\\partial f}{\\partial \\mathbf{A}} =  \\begin{bmatrix}\n",
    "\\frac{\\partial f}{\\partial \\mathbf{A}_{1,1}} & \\dots & \\frac{\\partial f}{\\partial \\mathbf{A}_{1,m}} \\\\\n",
    "\\vdots &  \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial f}{\\partial \\mathbf{A}_{n,1}} &  \\dots & \\frac{\\partial f}{\\partial \\mathbf{A}_{n,m}}\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Let $\\mathbf{X} \\in \\mathbb{R}^{N\\times d}$ be a matrix (sometimes also called the *design matrix*) whose rows are the observations of the dataset and let $\\mathbf{y} \\in \\mathbb{R}^{N}$ be the vector consisting of all values $y^{(i)}$ (i.e., $\\mathbf{X}^{(i,:)} = \\mathbf{x}^{(i)}$ and $\\mathbf{y}^{(i)} = y^{(i)}$). It can be verified that: \n",
    "\n",
    "\\begin{equation}\n",
    "J(\\mathbf{w}) = \\frac{1}{N}(\\mathbf{X}\\mathbf{w} - \\mathbf{y})^{T}(\\mathbf{X}\\mathbf{w} - \\mathbf{y})\n",
    "\\end{equation}\n",
    "\n",
    "Using basic matrix derivative concepts we can compute the gradient of $J(\\mathbf{w})$ with respect to $\\mathbf{w}$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_{\\mathbf{w}}J(\\mathbf{w}) = \\frac{2}{N} (\\mathbf{X}^{T}\\mathbf{X}\\mathbf{w} -\\mathbf{X}^{T}\\mathbf{y})   \n",
    "\\end{equation}\n",
    "\n",
    "Thus, when $\\nabla_{\\mathbf{w}}J(\\mathbf{w}) = 0$ we have \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{X}^{T}\\mathbf{X}\\mathbf{w} = \\mathbf{X}^{T}\\mathbf{y}\n",
    "\\end{equation}\n",
    "\n",
    "Hence,\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{w} = (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\mathbf{y}\n",
    "\\end{equation}\n",
    "\n",
    "Note that this solution has a high computational cost. As the number of variables (*features*) increases, the cost for matrix inversion becomes prohibitive. See  [this text](https://sgfin.github.io/files/notes/CS229_Lecture_Notes.pdf) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <mark>Exercise 1</mark>\n",
    "Using only **NumPy** (a quick introduction to this library can be found  [here](http://cs231n.github.io/python-numpy-tutorial/)), complete the two functions below. Recall that $\\mathbf{X} \\in \\mathbb{R}^{N\\times d}$; thus you will need to add a component of value 1 to each of  the observations in $\\mathbf{X}$ before performing the computation described above.\n",
    "\n",
    "NOTE: Although the dataset above has data of dimension $d=1$, your code must be generic (it should work for $d\\geq1$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>1.1. Weight computation function</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation_weights(X, y):\n",
    "    \"\"\"\n",
    "    Calculates the weights of a linear function using the normal equation method.\n",
    "    You should add into X a new column with 1s.\n",
    "\n",
    "    :param X: design matrix\n",
    "    :type X: np.ndarray(shape=(N, d))\n",
    "    :param y: regression targets\n",
    "    :type y: np.ndarray(shape=(N, 1))\n",
    "    :return: weight vector\n",
    "    :rtype: np.ndarray(shape=(d+1, 1))\n",
    "    \"\"\"\n",
    "    \n",
    "    # START OF YOUR CODE:\n",
    "    #raise NotImplementedError(\"Function normal_equation_weights() is not implemented\")\n",
    "    import numpy as np\n",
    "    from numpy.linalg import inv\n",
    "    Xt = X.T\n",
    "    X1 = inv(np.dot(Xt, X))\n",
    "    X2 = np.dot(X1, Xt)\n",
    "    w = np.dot(X2, y)\n",
    "    return(w)\n",
    "    \n",
    "    # END OF YOUR CODE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated w =\n",
      " [[64.40343]]\n"
     ]
    }
   ],
   "source": [
    "# test of function normal_equation_weights()\n",
    "\n",
    "w = 0  # this is not necessary\n",
    "w = normal_equation_weights(X, y)\n",
    "print(\"Estimated w =\\n\", w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>1.2. Prediction function</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,) and (101,) not aligned: 2 (dim 0) != 101 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-abe3ba5b072a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# END OF YOUR CODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mnormal_equation_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-abe3ba5b072a>\u001b[0m in \u001b[0;36mnormal_equation_prediction\u001b[0;34m(X, w)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (2,) and (101,) not aligned: 2 (dim 0) != 101 (dim 0)"
     ]
    }
   ],
   "source": [
    "def normal_equation_prediction(X, w):\n",
    "    \"\"\"\n",
    "    Calculates the prediction over a set of observations X using the linear function\n",
    "    characterized by the weight vector w.\n",
    "    You should add into X a new column with 1s.\n",
    "\n",
    "    :param X: design matrix\n",
    "    :type X: np.ndarray(shape=(N, d))\n",
    "    :param w: weight vector\n",
    "    :type w: np.ndarray(shape=(d+1, 1))\n",
    "    :param y: regression prediction\n",
    "    :type y: np.ndarray(shape=(N, 1))\n",
    "    \"\"\"\n",
    "    \n",
    "    # START OF YOUR CODE:\n",
    "    #raise NotImplementedError(\"Function normal_equation_prediction() is not implemented\")\n",
    "    numero_de_colunas = X.shape[1]\n",
    "    X1 = np.ones((1, numero_de_colunas))\n",
    "    X = np.append(X1, X)\n",
    "    w = np.append([0], w)\n",
    "    y = np.dot(w.T, X)\n",
    "    \n",
    "    return(y)\n",
    "    # END OF YOUR CODE\n",
    "\n",
    "normal_equation_prediction(X, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>1.3. Coefficient of determination</mark>\n",
    "We can use the [$R^2$](https://pt.wikipedia.org/wiki/R%C2%B2) metric (Coefficient of determination) to evaluate how well the linear model fits the data.\n",
    "\n",
    "**Which $𝑅^2$ value would you expect to observe ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# test of function normal_equation_prediction()\n",
    "prediction = normal_equation_prediction(X, w)\n",
    "\n",
    "# compute the R2 score using the r2_score function from sklearn\n",
    "# Replace 0 with an appropriate call of the function\n",
    "\n",
    "# START OF YOUR CODE:\n",
    "r_2 = 0\n",
    "# END OF YOUR CODE\n",
    "\n",
    "plot_points_regression(X,\n",
    "                       y,\n",
    "                       title='Real estate prices prediction',\n",
    "                       xlabel=\"m\\u00b2\",\n",
    "                       ylabel='$',\n",
    "                       prediction=prediction,\n",
    "                       legend=True,\n",
    "                       r_squared=r_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional tests\n",
    "\n",
    "Let us compute a prediction for $x=650$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us use the prediction function\n",
    "x = np.asarray([650]).reshape(1,1)\n",
    "prediction = normal_equation_prediction(x, w)\n",
    "print(\"Area = %.2f  Predicted price = %.4f\" %(x[0], prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>1.4. Processing time</mark>\n",
    "\n",
    "Experiment with different nummber of samples $N$ and observe how processing time varies.\n",
    "\n",
    "Be careful not to use a too large value; it may make jupyter freeze ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add other values for N\n",
    "# START OF YOUR CODE:\n",
    "N = [100] \n",
    "# END OF YOUR CODE\n",
    "\n",
    "for i in N:\n",
    "    X, y = get_housing_prices_data(N=i)\n",
    "    init = time.time()\n",
    "    w = normal_equation_weights(X, y)\n",
    "    prediction = normal_equation_prediction(X,w)\n",
    "    init = time.time() - init\n",
    "    \n",
    "    print(\"\\nExecution time = {:.8f}(s)\\n\".format(init))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <mark>Exercise 2</mark>\n",
    "\n",
    "Let us test the code with $𝑑>1$. \n",
    "We will use the data we have collected in our first class. The [file](https://edisciplinas.usp.br/pluginfile.php/5982803/course/section/6115454/QT1data.csv) can be found on e-disciplinas. \n",
    "\n",
    "Let us try to predict the weight based on one or more features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the dataset\n",
    "df = pd.read_csv('QT1data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our target variable is the weight\n",
    "y = df.pop('Weight').values\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>2.1. One feature ($d=1$)</mark>\n",
    "\n",
    "We will use 'Height' as the input feature and predict the weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['Height']\n",
    "X = df.loc[:, feature_cols]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the code for computing the following\n",
    "- compute the regression weights using $\\mathbf{X}$ and $\\mathbf{y}$\n",
    "- compute the prediction\n",
    "- compute the $R^2$ value\n",
    "- plot the regression graph (use appropriate values for the parameters of function <tt>plot_points_regression()</tt>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START OF YOUR CODE:\n",
    "\n",
    "# END OF YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>2.2 - Two input features ($d=2$)</mark>\n",
    "\n",
    "Now repeat the exercise with using as input the features 'Height' and 'Shoe number'\n",
    "\n",
    "- compute the regression weights using $\\mathbf{X}$ and $\\mathbf{y}$\n",
    "- compute the prediction\n",
    "- compute and print the $R^2$ value\n",
    "\n",
    "Note that our plotting function can not be used. There is no need to do plotting here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START OF YOUR CODE:\n",
    "\n",
    "# END OF YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - <mark>Three input features ($d=3$)</mark>\n",
    "\n",
    "Now try with three features. There is no need to do plotting here.\n",
    "- compute the regression weights using $\\mathbf{X}$ and $\\mathbf{y}$\n",
    "- compute the prediction\n",
    "- compute and print the $R^2$ value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START OF YOUR CODE:\n",
    "\n",
    "# END OF YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>2.4 - Your comments</mark>\n",
    "\n",
    "Did you observe anything interesting with varying values of $d$ ? Comment about it.\n",
    "\n",
    "YOUR COMMENT BELOW:\n",
    "\n",
    "===>\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
