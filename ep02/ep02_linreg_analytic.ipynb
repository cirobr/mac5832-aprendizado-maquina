{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name:  Ciro B Rosa / No USP 2320769\n",
      "\n",
      "Honor pledge:  I affirm that I have not given or received any unauthorized help on this assignment, and that this work is my own.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "name = \"Ciro B Rosa / No USP 2320769\"  # write YOUR NAME\n",
    "\n",
    "honorPledge = \"I affirm that I have not given or received any unauthorized \" \\\n",
    "              \"help on this assignment, and that this work is my own.\\n\"\n",
    "\n",
    "\n",
    "print(\"\\nName: \", name)\n",
    "print(\"\\nHonor pledge: \", honorPledge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAC0460 / MAC5832 (2021)\n",
    "<hr>\n",
    "\n",
    "# EP2: Linear regression - analytic solution\n",
    "\n",
    "### Objectives:\n",
    "\n",
    "- to implement and test the analytic solution for the linear regression task (see, for instance, <a href=\"http://work.caltech.edu/slides/slides03.pdf\">Slides of Lecture 03</a> and Lecture 03 of *Learning from Data*)\n",
    "- to understand the core idea (*optimization of a loss or cost function*) for parameter adjustment in machine learning\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression\n",
    "\n",
    "Given a dataset $\\{(\\mathbf{x}^{(1)}, y^{(1)}), \\dots ,(\\mathbf{x}^{(N)}, y^{(N)})\\}$ with $\\mathbf{x}^{(i)} \\in \\mathbb{R}^{d}$ and $y^{(i)} \\in \\mathbb{R}$, we would like to approximate the unknown function $f:\\mathbb{R}^{d} \\rightarrow \\mathbb{R}$ (recall that $y^{(i)} =f(\\mathbf{x}^{(i)})$) by means of a linear model $h$:\n",
    "$$\n",
    "h(\\mathbf{x}^{(i)}; \\mathbf{w}, b) = \\mathbf{w}^\\top  \\mathbf{x}^{(i)} + b\n",
    "$$\n",
    "\n",
    "Note that $h(\\mathbf{x}^{(i)}; \\mathbf{w}, b)$ is, in fact, an  [affine transformation](https://en.wikipedia.org/wiki/Affine_transformation) of  $\\mathbf{x}^{(i)}$. As commonly done, we will use the term \"linear\" to refer to an affine transformation.\n",
    "\n",
    "The output of $h$ is a linear transformation of $\\mathbf{x}^{(i)}$. We use the notation $h(\\mathbf{x}^{(i)}; \\mathbf{w}, b)$ to make clear that $h$ is a parametric model, i.e., the transformation $h$ is defined  by the parameters $\\mathbf{w}$ and $b$. We can view vector $\\mathbf{w}$ as a *weight* vector that controls the effect of each *feature* in the prediction.\n",
    "\n",
    "By adding one component with value equal to 1 to the observations $\\mathbf{x}$ (an artificial coordinate), we have:\n",
    "\n",
    "$$\\tilde{\\mathbf{x}} = (1, x_1, \\ldots, x_d) \\in \\mathbb{R}^{1+d}$$\n",
    "\n",
    "and then we can simplify the notation:\n",
    "$$\n",
    "h(\\mathbf{x}^{(i)}; \\mathbf{w}) = \\hat{y}^{(i)} = \\mathbf{w}^\\top  \\tilde{\\mathbf{x}}^{(i)}\n",
    "$$\n",
    "\n",
    "We would like to determine the optimal parameters $\\mathbf{w}$ such that prediction $\\hat{y}^{(i)}$ is as closest as possible to $y^{(i)}$ according to some error metric. Adopting the *mean square error* as such metric we have the following cost function:\n",
    "\n",
    "\\begin{equation}\n",
    "J(\\mathbf{w}) = \\frac{1}{N}\\sum_{i=1}^{N}\\big(\\hat{y}^{(i)} - y^{(i)}\\big)^{2}\n",
    "\\end{equation}\n",
    "\n",
    "Thus, the task of determining a function $h$ that is closest to $f$ is reduced to the task of finding the values $\\mathbf{w}$ that minimize $J(\\mathbf{w})$.\n",
    "\n",
    "**Now we will explore this model, starting with a simple dataset.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some imports\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An auxiliary function\n",
    "def get_housing_prices_data(N, verbose=True):\n",
    "    \"\"\"\n",
    "    Generates artificial linear data,\n",
    "    where x = square meter, y = house price\n",
    "\n",
    "    :param N: data set size\n",
    "    :type N: int\n",
    "    \n",
    "    :param verbose: param to control print\n",
    "    :type verbose: bool\n",
    "    :return: design matrix, regression targets\n",
    "    :rtype: np.array, np.array\n",
    "    \"\"\"\n",
    "    cond = False\n",
    "    while not cond:\n",
    "        x = np.linspace(90, 1200, N)\n",
    "        gamma = np.random.normal(30, 10, x.size)\n",
    "        y = 50 * x + gamma * 400\n",
    "        x = x.astype(\"float32\")\n",
    "        x = x.reshape((x.shape[0], 1))\n",
    "        y = y.astype(\"float32\")\n",
    "        y = y.reshape((y.shape[0], 1))\n",
    "        cond = min(y) > 0\n",
    "        \n",
    "    xmean, xsdt, xmax, xmin = np.mean(x), np.std(x), np.max(x), np.min(x)\n",
    "    ymean, ysdt, ymax, ymin = np.mean(y), np.std(y), np.max(y), np.min(y)\n",
    "    if verbose:\n",
    "        print(\"\\nX shape = {}\".format(x.shape))\n",
    "        print(\"y shape = {}\\n\".format(y.shape))\n",
    "        print(\"X: mean {}, sdt {:.2f}, max {:.2f}, min {:.2f}\".format(xmean,\n",
    "                                                               xsdt,\n",
    "                                                               xmax,\n",
    "                                                               xmin))\n",
    "        print(\"y: mean {:.2f}, sdt {:.2f}, max {:.2f}, min {:.2f}\".format(ymean,\n",
    "                                                                 ysdt,\n",
    "                                                                 ymax,\n",
    "                                                                 ymin))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another auxiliary function\n",
    "def plot_points_regression(x,\n",
    "                           y,\n",
    "                           title,\n",
    "                           xlabel,\n",
    "                           ylabel,\n",
    "                           prediction=None,\n",
    "                           legend=False,\n",
    "                           r_squared=None,\n",
    "                           position=(90, 100)):\n",
    "    \"\"\"\n",
    "    Plots the data points and the prediction,\n",
    "    if there is one.\n",
    "\n",
    "    :param x: design matrix\n",
    "    :type x: np.array\n",
    "    :param y: regression targets\n",
    "    :type y: np.array\n",
    "    :param title: plot's title\n",
    "    :type title: str\n",
    "    :param xlabel: x axis label\n",
    "    :type xlabel: str\n",
    "    :param ylabel: y axis label\n",
    "    :type ylabel: str\n",
    "    :param prediction: model's prediction\n",
    "    :type prediction: np.array\n",
    "    :param legend: param to control print legends\n",
    "    :type legend: bool\n",
    "    :param r_squared: r^2 value\n",
    "    :type r_squared: float\n",
    "    :param position: text position\n",
    "    :type position: tuple\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "    line1, = ax.plot(x, y, 'bo', label='Real data')\n",
    "    if prediction is not None:\n",
    "        line2, = ax.plot(x, prediction, 'r', label='Predicted data')\n",
    "        if legend:\n",
    "            plt.legend(handles=[line1, line2], loc=2)\n",
    "        ax.set_title(title,\n",
    "                 fontsize=20,\n",
    "                 fontweight='bold')\n",
    "    if r_squared is not None:\n",
    "        bbox_props = dict(boxstyle=\"square,pad=0.3\",\n",
    "                          fc=\"white\", ec=\"black\", lw=0.2)\n",
    "        t = ax.text(position[0], position[1], \"$R^2 ={:.4f}$\".format(r_squared),\n",
    "                    size=15, bbox=bbox_props)\n",
    "\n",
    "    ax.set_xlabel(xlabel, fontsize=20)\n",
    "    ax.set_ylabel(ylabel, fontsize=20)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset \n",
    "\n",
    "The first dataset we will use is a toy dataset. We will generate $N=100$ observations with only one *feature* and a real value associated to each of them. We can view these observations as being pairs *(area of a real state in square meters, price of the real state)*. Our task is to construct a model that is able to predict the price of a real state, given its area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X shape = (100, 1)\n",
      "y shape = (100, 1)\n",
      "\n",
      "X: mean 645.0, sdt 323.65, max 1200.00, min 90.00\n",
      "y: mean 44193.54, sdt 17215.40, max 76864.29, min 9000.84\n"
     ]
    }
   ],
   "source": [
    "X, y = get_housing_prices_data(N=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_points_regression(X,\n",
    "                       y,\n",
    "                       title='Real estate prices prediction',\n",
    "                       xlabel=\"m\\u00b2\",\n",
    "                       ylabel='$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The solution\n",
    "\n",
    "Given $f:\\mathbb{R}^{N\\times M} \\rightarrow \\mathbb{R}$ and $\\mathbf{A} \\in \\mathbb{R}^{N\\times M}$, we define the gradient of $f$ with respect to $\\mathbf{A}$ as:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\nabla_{\\mathbf{A}}f = \\frac{\\partial f}{\\partial \\mathbf{A}} =  \\begin{bmatrix}\n",
    "\\frac{\\partial f}{\\partial \\mathbf{A}_{1,1}} & \\dots & \\frac{\\partial f}{\\partial \\mathbf{A}_{1,m}} \\\\\n",
    "\\vdots &  \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial f}{\\partial \\mathbf{A}_{n,1}} &  \\dots & \\frac{\\partial f}{\\partial \\mathbf{A}_{n,m}}\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Let $\\mathbf{X} \\in \\mathbb{R}^{N\\times d}$ be a matrix (sometimes also called the *design matrix*) whose rows are the observations of the dataset and let $\\mathbf{y} \\in \\mathbb{R}^{N}$ be the vector consisting of all values $y^{(i)}$ (i.e., $\\mathbf{X}^{(i,:)} = \\mathbf{x}^{(i)}$ and $\\mathbf{y}^{(i)} = y^{(i)}$). It can be verified that: \n",
    "\n",
    "\\begin{equation}\n",
    "J(\\mathbf{w}) = \\frac{1}{N}(\\mathbf{X}\\mathbf{w} - \\mathbf{y})^{T}(\\mathbf{X}\\mathbf{w} - \\mathbf{y})\n",
    "\\end{equation}\n",
    "\n",
    "Using basic matrix derivative concepts we can compute the gradient of $J(\\mathbf{w})$ with respect to $\\mathbf{w}$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_{\\mathbf{w}}J(\\mathbf{w}) = \\frac{2}{N} (\\mathbf{X}^{T}\\mathbf{X}\\mathbf{w} -\\mathbf{X}^{T}\\mathbf{y})   \n",
    "\\end{equation}\n",
    "\n",
    "Thus, when $\\nabla_{\\mathbf{w}}J(\\mathbf{w}) = 0$ we have \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{X}^{T}\\mathbf{X}\\mathbf{w} = \\mathbf{X}^{T}\\mathbf{y}\n",
    "\\end{equation}\n",
    "\n",
    "Hence,\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{w} = (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\mathbf{y}\n",
    "\\end{equation}\n",
    "\n",
    "Note that this solution has a high computational cost. As the number of variables (*features*) increases, the cost for matrix inversion becomes prohibitive. See  [this text](https://sgfin.github.io/files/notes/CS229_Lecture_Notes.pdf) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <mark>Exercise 1</mark>\n",
    "Using only **NumPy** (a quick introduction to this library can be found  [here](http://cs231n.github.io/python-numpy-tutorial/)), complete the two functions below. Recall that $\\mathbf{X} \\in \\mathbb{R}^{N\\times d}$; thus you will need to add a component of value 1 to each of  the observations in $\\mathbf{X}$ before performing the computation described above.\n",
    "\n",
    "NOTE: Although the dataset above has data of dimension $d=1$, your code must be generic (it should work for $d\\geq1$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>1.1. Weight computation function</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation_weights(X, y):\n",
    "    \"\"\"\n",
    "    Calculates the weights of a linear function using the normal equation method.\n",
    "    You should add into X a new column with 1s.\n",
    "\n",
    "    :param X: design matrix\n",
    "    :type X: np.ndarray(shape=(N, d))\n",
    "    :param y: regression targets\n",
    "    :type y: np.ndarray(shape=(N, 1))\n",
    "    :return: weight vector\n",
    "    :rtype: np.ndarray(shape=(d+1, 1))\n",
    "    \"\"\"\n",
    "    \n",
    "    # START OF YOUR CODE:\n",
    "    #raise NotImplementedError(\"Function normal_equation_weights() is not implemented\")\n",
    "    import numpy as np\n",
    "    from numpy.linalg import inv\n",
    "    Xt = X.T\n",
    "    X1 = inv(np.dot(Xt, X))\n",
    "    X2 = np.dot(X1, Xt)\n",
    "    w = np.dot(X2, y)\n",
    "    \n",
    "    b = np.array(0).astype(\"float32\")\n",
    "    w = np.append(b, w).astype(\"float32\")\n",
    "    w = w.reshape(X.shape[1]+1, 1)\n",
    "    return(w)\n",
    "\n",
    "    # END OF YOUR CODE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated w =\n",
      " [[ 0.    ]\n",
      " [65.1245]]\n"
     ]
    }
   ],
   "source": [
    "# test of function normal_equation_weights()\n",
    "\n",
    "w = 0  # this is not necessary\n",
    "w = normal_equation_weights(X, y)\n",
    "print(\"Estimated w =\\n\", w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>1.2. Prediction function</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation_prediction(X, w):\n",
    "    \"\"\"\n",
    "    Calculates the prediction over a set of observations X using the linear function\n",
    "    characterized by the weight vector w.\n",
    "    You should add into X a new column with 1s.\n",
    "\n",
    "    :param X: design matrix\n",
    "    :type X: np.ndarray(shape=(N, d))\n",
    "    :param w: weight vector\n",
    "    :type w: np.ndarray(shape=(d+1, 1))\n",
    "    :param y: regression prediction\n",
    "    :type y: np.ndarray(shape=(N, 1))\n",
    "    \"\"\"\n",
    "    \n",
    "    # START OF YOUR CODE:\n",
    "    raise NotImplementedError(\"Function normal_equation_prediction() is not implemented\")\n",
    "    # END OF YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>1.3. Coefficient of determination</mark>\n",
    "We can use the [$R^2$](https://pt.wikipedia.org/wiki/R%C2%B2) metric (Coefficient of determination) to evaluate how well the linear model fits the data.\n",
    "\n",
    "**Which $𝑅^2$ value would you expect to observe ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# test of function normal_equation_prediction()\n",
    "prediction = normal_equation_prediction(X, w)\n",
    "\n",
    "# compute the R2 score using the r2_score function from sklearn\n",
    "# Replace 0 with an appropriate call of the function\n",
    "\n",
    "# START OF YOUR CODE:\n",
    "r_2 = 0\n",
    "# END OF YOUR CODE\n",
    "\n",
    "plot_points_regression(X,\n",
    "                       y,\n",
    "                       title='Real estate prices prediction',\n",
    "                       xlabel=\"m\\u00b2\",\n",
    "                       ylabel='$',\n",
    "                       prediction=prediction,\n",
    "                       legend=True,\n",
    "                       r_squared=r_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional tests\n",
    "\n",
    "Let us compute a prediction for $x=650$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us use the prediction function\n",
    "x = np.asarray([650]).reshape(1,1)\n",
    "prediction = normal_equation_prediction(x, w)\n",
    "print(\"Area = %.2f  Predicted price = %.4f\" %(x[0], prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>1.4. Processing time</mark>\n",
    "\n",
    "Experiment with different nummber of samples $N$ and observe how processing time varies.\n",
    "\n",
    "Be careful not to use a too large value; it may make jupyter freeze ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add other values for N\n",
    "# START OF YOUR CODE:\n",
    "N = [100] \n",
    "# END OF YOUR CODE\n",
    "\n",
    "for i in N:\n",
    "    X, y = get_housing_prices_data(N=i)\n",
    "    init = time.time()\n",
    "    w = normal_equation_weights(X, y)\n",
    "    prediction = normal_equation_prediction(X,w)\n",
    "    init = time.time() - init\n",
    "    \n",
    "    print(\"\\nExecution time = {:.8f}(s)\\n\".format(init))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <mark>Exercise 2</mark>\n",
    "\n",
    "Let us test the code with $𝑑>1$. \n",
    "We will use the data we have collected in our first class. The [file](https://edisciplinas.usp.br/pluginfile.php/5982803/course/section/6115454/QT1data.csv) can be found on e-disciplinas. \n",
    "\n",
    "Let us try to predict the weight based on one or more features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the dataset\n",
    "df = pd.read_csv('QT1data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our target variable is the weight\n",
    "y = df.pop('Weight').values\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>2.1. One feature ($d=1$)</mark>\n",
    "\n",
    "We will use 'Height' as the input feature and predict the weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['Height']\n",
    "X = df.loc[:, feature_cols]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the code for computing the following\n",
    "- compute the regression weights using $\\mathbf{X}$ and $\\mathbf{y}$\n",
    "- compute the prediction\n",
    "- compute the $R^2$ value\n",
    "- plot the regression graph (use appropriate values for the parameters of function <tt>plot_points_regression()</tt>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START OF YOUR CODE:\n",
    "\n",
    "# END OF YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>2.2 - Two input features ($d=2$)</mark>\n",
    "\n",
    "Now repeat the exercise with using as input the features 'Height' and 'Shoe number'\n",
    "\n",
    "- compute the regression weights using $\\mathbf{X}$ and $\\mathbf{y}$\n",
    "- compute the prediction\n",
    "- compute and print the $R^2$ value\n",
    "\n",
    "Note that our plotting function can not be used. There is no need to do plotting here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START OF YOUR CODE:\n",
    "\n",
    "# END OF YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - <mark>Three input features ($d=3$)</mark>\n",
    "\n",
    "Now try with three features. There is no need to do plotting here.\n",
    "- compute the regression weights using $\\mathbf{X}$ and $\\mathbf{y}$\n",
    "- compute the prediction\n",
    "- compute and print the $R^2$ value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START OF YOUR CODE:\n",
    "\n",
    "# END OF YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>2.4 - Your comments</mark>\n",
    "\n",
    "Did you observe anything interesting with varying values of $d$ ? Comment about it.\n",
    "\n",
    "YOUR COMMENT BELOW:\n",
    "\n",
    "===>\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
