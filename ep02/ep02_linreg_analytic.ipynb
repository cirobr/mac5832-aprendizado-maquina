{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name:  Ciro B Rosa / No USP 2320769\n",
      "\n",
      "Honor pledge:  I affirm that I have not given or received any unauthorized help on this assignment, and that this work is my own.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "name = \"Ciro B Rosa / No USP 2320769\"  # write YOUR NAME\n",
    "\n",
    "honorPledge = \"I affirm that I have not given or received any unauthorized \" \\\n",
    "              \"help on this assignment, and that this work is my own.\\n\"\n",
    "\n",
    "\n",
    "print(\"\\nName: \", name)\n",
    "print(\"\\nHonor pledge: \", honorPledge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAC0460 / MAC5832 (2021)\n",
    "<hr>\n",
    "\n",
    "# EP2: Linear regression - analytic solution\n",
    "\n",
    "### Objectives:\n",
    "\n",
    "- to implement and test the analytic solution for the linear regression task (see, for instance, <a href=\"http://work.caltech.edu/slides/slides03.pdf\">Slides of Lecture 03</a> and Lecture 03 of *Learning from Data*)\n",
    "- to understand the core idea (*optimization of a loss or cost function*) for parameter adjustment in machine learning\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression\n",
    "\n",
    "Given a dataset $\\{(\\mathbf{x}^{(1)}, y^{(1)}), \\dots ,(\\mathbf{x}^{(N)}, y^{(N)})\\}$ with $\\mathbf{x}^{(i)} \\in \\mathbb{R}^{d}$ and $y^{(i)} \\in \\mathbb{R}$, we would like to approximate the unknown function $f:\\mathbb{R}^{d} \\rightarrow \\mathbb{R}$ (recall that $y^{(i)} =f(\\mathbf{x}^{(i)})$) by means of a linear model $h$:\n",
    "$$\n",
    "h(\\mathbf{x}^{(i)}; \\mathbf{w}, b) = \\mathbf{w}^\\top  \\mathbf{x}^{(i)} + b\n",
    "$$\n",
    "\n",
    "Note that $h(\\mathbf{x}^{(i)}; \\mathbf{w}, b)$ is, in fact, an  [affine transformation](https://en.wikipedia.org/wiki/Affine_transformation) of  $\\mathbf{x}^{(i)}$. As commonly done, we will use the term \"linear\" to refer to an affine transformation.\n",
    "\n",
    "The output of $h$ is a linear transformation of $\\mathbf{x}^{(i)}$. We use the notation $h(\\mathbf{x}^{(i)}; \\mathbf{w}, b)$ to make clear that $h$ is a parametric model, i.e., the transformation $h$ is defined  by the parameters $\\mathbf{w}$ and $b$. We can view vector $\\mathbf{w}$ as a *weight* vector that controls the effect of each *feature* in the prediction.\n",
    "\n",
    "By adding one component with value equal to 1 to the observations $\\mathbf{x}$ (an artificial coordinate), we have:\n",
    "\n",
    "$$\\tilde{\\mathbf{x}} = (1, x_1, \\ldots, x_d) \\in \\mathbb{R}^{1+d}$$\n",
    "\n",
    "and then we can simplify the notation:\n",
    "$$\n",
    "h(\\mathbf{x}^{(i)}; \\mathbf{w}) = \\hat{y}^{(i)} = \\mathbf{w}^\\top  \\tilde{\\mathbf{x}}^{(i)}\n",
    "$$\n",
    "\n",
    "We would like to determine the optimal parameters $\\mathbf{w}$ such that prediction $\\hat{y}^{(i)}$ is as closest as possible to $y^{(i)}$ according to some error metric. Adopting the *mean square error* as such metric we have the following cost function:\n",
    "\n",
    "\\begin{equation}\n",
    "J(\\mathbf{w}) = \\frac{1}{N}\\sum_{i=1}^{N}\\big(\\hat{y}^{(i)} - y^{(i)}\\big)^{2}\n",
    "\\end{equation}\n",
    "\n",
    "Thus, the task of determining a function $h$ that is closest to $f$ is reduced to the task of finding the values $\\mathbf{w}$ that minimize $J(\\mathbf{w})$.\n",
    "\n",
    "**Now we will explore this model, starting with a simple dataset.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some imports\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An auxiliary function\n",
    "def get_housing_prices_data(N, verbose=True):\n",
    "    \"\"\"\n",
    "    Generates artificial linear data,\n",
    "    where x = square meter, y = house price\n",
    "\n",
    "    :param N: data set size\n",
    "    :type N: int\n",
    "    \n",
    "    :param verbose: param to control print\n",
    "    :type verbose: bool\n",
    "    :return: design matrix, regression targets\n",
    "    :rtype: np.array, np.array\n",
    "    \"\"\"\n",
    "    cond = False\n",
    "    while not cond:\n",
    "        x = np.linspace(90, 1200, N)\n",
    "        gamma = np.random.normal(30, 10, x.size)\n",
    "        y = 50 * x + gamma * 400\n",
    "        x = x.astype(\"float32\")\n",
    "        x = x.reshape((x.shape[0], 1))\n",
    "        y = y.astype(\"float32\")\n",
    "        y = y.reshape((y.shape[0], 1))\n",
    "        cond = min(y) > 0\n",
    "        \n",
    "    xmean, xsdt, xmax, xmin = np.mean(x), np.std(x), np.max(x), np.min(x)\n",
    "    ymean, ysdt, ymax, ymin = np.mean(y), np.std(y), np.max(y), np.min(y)\n",
    "    if verbose:\n",
    "        print(\"\\nX shape = {}\".format(x.shape))\n",
    "        print(\"y shape = {}\\n\".format(y.shape))\n",
    "        print(\"X: mean {}, sdt {:.2f}, max {:.2f}, min {:.2f}\".format(xmean,\n",
    "                                                               xsdt,\n",
    "                                                               xmax,\n",
    "                                                               xmin))\n",
    "        print(\"y: mean {:.2f}, sdt {:.2f}, max {:.2f}, min {:.2f}\".format(ymean,\n",
    "                                                                 ysdt,\n",
    "                                                                 ymax,\n",
    "                                                                 ymin))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another auxiliary function\n",
    "def plot_points_regression(x,\n",
    "                           y,\n",
    "                           title,\n",
    "                           xlabel,\n",
    "                           ylabel,\n",
    "                           prediction=None,\n",
    "                           legend=False,\n",
    "                           r_squared=None,\n",
    "                           position=(90, 100)):\n",
    "    \"\"\"\n",
    "    Plots the data points and the prediction,\n",
    "    if there is one.\n",
    "\n",
    "    :param x: design matrix\n",
    "    :type x: np.array\n",
    "    :param y: regression targets\n",
    "    :type y: np.array\n",
    "    :param title: plot's title\n",
    "    :type title: str\n",
    "    :param xlabel: x axis label\n",
    "    :type xlabel: str\n",
    "    :param ylabel: y axis label\n",
    "    :type ylabel: str\n",
    "    :param prediction: model's prediction\n",
    "    :type prediction: np.array\n",
    "    :param legend: param to control print legends\n",
    "    :type legend: bool\n",
    "    :param r_squared: r^2 value\n",
    "    :type r_squared: float\n",
    "    :param position: text position\n",
    "    :type position: tuple\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "    line1, = ax.plot(x, y, 'bo', label='Real data')\n",
    "    if prediction is not None:\n",
    "        line2, = ax.plot(x, prediction, 'r', label='Predicted data')\n",
    "        if legend:\n",
    "            plt.legend(handles=[line1, line2], loc=2)\n",
    "        ax.set_title(title,\n",
    "                 fontsize=20,\n",
    "                 fontweight='bold')\n",
    "    if r_squared is not None:\n",
    "        bbox_props = dict(boxstyle=\"square,pad=0.3\",\n",
    "                          fc=\"white\", ec=\"black\", lw=0.2)\n",
    "        t = ax.text(position[0], position[1], \"$R^2 ={:.4f}$\".format(r_squared),\n",
    "                    size=15, bbox=bbox_props)\n",
    "\n",
    "    ax.set_xlabel(xlabel, fontsize=20)\n",
    "    ax.set_ylabel(ylabel, fontsize=20)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset \n",
    "\n",
    "The first dataset we will use is a toy dataset. We will generate $N=100$ observations with only one *feature* and a real value associated to each of them. We can view these observations as being pairs *(area of a real state in square meters, price of the real state)*. Our task is to construct a model that is able to predict the price of a real state, given its area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X shape = (100, 1)\n",
      "y shape = (100, 1)\n",
      "\n",
      "X: mean 645.0, sdt 323.65, max 1200.00, min 90.00\n",
      "y: mean 44057.75, sdt 16661.33, max 77324.73, min 12116.32\n"
     ]
    }
   ],
   "source": [
    "X, y = get_housing_prices_data(N=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_points_regression(X,\n",
    "                       y,\n",
    "                       title='Real estate prices prediction',\n",
    "                       xlabel=\"m\\u00b2\",\n",
    "                       ylabel='$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The solution\n",
    "\n",
    "Given $f:\\mathbb{R}^{N\\times M} \\rightarrow \\mathbb{R}$ and $\\mathbf{A} \\in \\mathbb{R}^{N\\times M}$, we define the gradient of $f$ with respect to $\\mathbf{A}$ as:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\nabla_{\\mathbf{A}}f = \\frac{\\partial f}{\\partial \\mathbf{A}} =  \\begin{bmatrix}\n",
    "\\frac{\\partial f}{\\partial \\mathbf{A}_{1,1}} & \\dots & \\frac{\\partial f}{\\partial \\mathbf{A}_{1,m}} \\\\\n",
    "\\vdots &  \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial f}{\\partial \\mathbf{A}_{n,1}} &  \\dots & \\frac{\\partial f}{\\partial \\mathbf{A}_{n,m}}\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Let $\\mathbf{X} \\in \\mathbb{R}^{N\\times d}$ be a matrix (sometimes also called the *design matrix*) whose rows are the observations of the dataset and let $\\mathbf{y} \\in \\mathbb{R}^{N}$ be the vector consisting of all values $y^{(i)}$ (i.e., $\\mathbf{X}^{(i,:)} = \\mathbf{x}^{(i)}$ and $\\mathbf{y}^{(i)} = y^{(i)}$). It can be verified that: \n",
    "\n",
    "\\begin{equation}\n",
    "J(\\mathbf{w}) = \\frac{1}{N}(\\mathbf{X}\\mathbf{w} - \\mathbf{y})^{T}(\\mathbf{X}\\mathbf{w} - \\mathbf{y})\n",
    "\\end{equation}\n",
    "\n",
    "Using basic matrix derivative concepts we can compute the gradient of $J(\\mathbf{w})$ with respect to $\\mathbf{w}$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_{\\mathbf{w}}J(\\mathbf{w}) = \\frac{2}{N} (\\mathbf{X}^{T}\\mathbf{X}\\mathbf{w} -\\mathbf{X}^{T}\\mathbf{y})   \n",
    "\\end{equation}\n",
    "\n",
    "Thus, when $\\nabla_{\\mathbf{w}}J(\\mathbf{w}) = 0$ we have \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{X}^{T}\\mathbf{X}\\mathbf{w} = \\mathbf{X}^{T}\\mathbf{y}\n",
    "\\end{equation}\n",
    "\n",
    "Hence,\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{w} = (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\mathbf{y}\n",
    "\\end{equation}\n",
    "\n",
    "Note that this solution has a high computational cost. As the number of variables (*features*) increases, the cost for matrix inversion becomes prohibitive. See  [this text](https://sgfin.github.io/files/notes/CS229_Lecture_Notes.pdf) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <mark>Exercise 1</mark>\n",
    "Using only **NumPy** (a quick introduction to this library can be found  [here](http://cs231n.github.io/python-numpy-tutorial/)), complete the two functions below. Recall that $\\mathbf{X} \\in \\mathbb{R}^{N\\times d}$; thus you will need to add a component of value 1 to each of  the observations in $\\mathbf{X}$ before performing the computation described above.\n",
    "\n",
    "NOTE: Although the dataset above has data of dimension $d=1$, your code must be generic (it should work for $d\\geq1$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>1.1. Weight computation function</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation_weights(X, y):\n",
    "    \"\"\"\n",
    "    Calculates the weights of a linear function using the normal equation method.\n",
    "    You should add into X a new column with 1s.\n",
    "\n",
    "    :param X: design matrix\n",
    "    :type X: np.ndarray(shape=(N, d))\n",
    "    :param y: regression targets\n",
    "    :type y: np.ndarray(shape=(N, 1))\n",
    "    :return: weight vector\n",
    "    :rtype: np.ndarray(shape=(d+1, 1))\n",
    "    \"\"\"\n",
    "    \n",
    "    # START OF YOUR CODE:\n",
    "    #raise NotImplementedError(\"Function normal_equation_weights() is not implemented\")\n",
    "    import numpy as np\n",
    "    from numpy.linalg import inv\n",
    "    Xt = X.T\n",
    "    X1 = inv(np.dot(Xt, X))\n",
    "    X2 = np.dot(X1, Xt)\n",
    "    w = np.dot(X2, y)\n",
    "    return(w)\n",
    "    \n",
    "    # END OF YOUR CODE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated w =\n",
      " [[64.63787]]\n"
     ]
    }
   ],
   "source": [
    "# test of function normal_equation_weights()\n",
    "\n",
    "w = 0  # this is not necessary\n",
    "w = normal_equation_weights(X, y)\n",
    "print(\"Estimated w =\\n\", w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>1.2. Prediction function</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,) and (101,) not aligned: 2 (dim 0) != 101 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-abe3ba5b072a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# END OF YOUR CODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mnormal_equation_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-abe3ba5b072a>\u001b[0m in \u001b[0;36mnormal_equation_prediction\u001b[0;34m(X, w)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (2,) and (101,) not aligned: 2 (dim 0) != 101 (dim 0)"
     ]
    }
   ],
   "source": [
    "def normal_equation_prediction(X, w):\n",
    "    \"\"\"\n",
    "    Calculates the prediction over a set of observations X using the linear function\n",
    "    characterized by the weight vector w.\n",
    "    You should add into X a new column with 1s.\n",
    "\n",
    "    :param X: design matrix\n",
    "    :type X: np.ndarray(shape=(N, d))\n",
    "    :param w: weight vector\n",
    "    :type w: np.ndarray(shape=(d+1, 1))\n",
    "    :param y: regression prediction\n",
    "    :type y: np.ndarray(shape=(N, 1))\n",
    "    \"\"\"\n",
    "    \n",
    "    # START OF YOUR CODE:\n",
    "    #raise NotImplementedError(\"Function normal_equation_prediction() is not implemented\")\n",
    "    numero_de_colunas = X.shape[1]\n",
    "    X1 = np.ones((1, numero_de_colunas))\n",
    "    X = np.append(X1, X)\n",
    "    w = np.append([0], w)\n",
    "    y = np.dot(w.T, X)\n",
    "    \n",
    "    return(y)\n",
    "    # END OF YOUR CODE\n",
    "\n",
    "normal_equation_prediction(X, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>1.3. Coefficient of determination</mark>\n",
    "We can use the [$R^2$](https://pt.wikipedia.org/wiki/R%C2%B2) metric (Coefficient of determination) to evaluate how well the linear model fits the data.\n",
    "\n",
    "**Which $𝑅^2$ value would you expect to observe ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# test of function normal_equation_prediction()\n",
    "prediction = normal_equation_prediction(X, w)\n",
    "\n",
    "# compute the R2 score using the r2_score function from sklearn\n",
    "# Replace 0 with an appropriate call of the function\n",
    "\n",
    "# START OF YOUR CODE:\n",
    "r_2 = 0\n",
    "# END OF YOUR CODE\n",
    "\n",
    "plot_points_regression(X,\n",
    "                       y,\n",
    "                       title='Real estate prices prediction',\n",
    "                       xlabel=\"m\\u00b2\",\n",
    "                       ylabel='$',\n",
    "                       prediction=prediction,\n",
    "                       legend=True,\n",
    "                       r_squared=r_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional tests\n",
    "\n",
    "Let us compute a prediction for $x=650$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us use the prediction function\n",
    "x = np.asarray([650]).reshape(1,1)\n",
    "prediction = normal_equation_prediction(x, w)\n",
    "print(\"Area = %.2f  Predicted price = %.4f\" %(x[0], prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>1.4. Processing time</mark>\n",
    "\n",
    "Experiment with different nummber of samples $N$ and observe how processing time varies.\n",
    "\n",
    "Be careful not to use a too large value; it may make jupyter freeze ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add other values for N\n",
    "# START OF YOUR CODE:\n",
    "N = [100] \n",
    "# END OF YOUR CODE\n",
    "\n",
    "for i in N:\n",
    "    X, y = get_housing_prices_data(N=i)\n",
    "    init = time.time()\n",
    "    w = normal_equation_weights(X, y)\n",
    "    prediction = normal_equation_prediction(X,w)\n",
    "    init = time.time() - init\n",
    "    \n",
    "    print(\"\\nExecution time = {:.8f}(s)\\n\".format(init))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <mark>Exercise 2</mark>\n",
    "\n",
    "Let us test the code with $𝑑>1$. \n",
    "We will use the data we have collected in our first class. The [file](https://edisciplinas.usp.br/pluginfile.php/5982803/course/section/6115454/QT1data.csv) can be found on e-disciplinas. \n",
    "\n",
    "Let us try to predict the weight based on one or more features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the dataset\n",
    "df = pd.read_csv('QT1data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our target variable is the weight\n",
    "y = df.pop('Weight').values\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>2.1. One feature ($d=1$)</mark>\n",
    "\n",
    "We will use 'Height' as the input feature and predict the weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['Height']\n",
    "X = df.loc[:, feature_cols]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the code for computing the following\n",
    "- compute the regression weights using $\\mathbf{X}$ and $\\mathbf{y}$\n",
    "- compute the prediction\n",
    "- compute the $R^2$ value\n",
    "- plot the regression graph (use appropriate values for the parameters of function <tt>plot_points_regression()</tt>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START OF YOUR CODE:\n",
    "\n",
    "# END OF YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>2.2 - Two input features ($d=2$)</mark>\n",
    "\n",
    "Now repeat the exercise with using as input the features 'Height' and 'Shoe number'\n",
    "\n",
    "- compute the regression weights using $\\mathbf{X}$ and $\\mathbf{y}$\n",
    "- compute the prediction\n",
    "- compute and print the $R^2$ value\n",
    "\n",
    "Note that our plotting function can not be used. There is no need to do plotting here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START OF YOUR CODE:\n",
    "\n",
    "# END OF YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - <mark>Three input features ($d=3$)</mark>\n",
    "\n",
    "Now try with three features. There is no need to do plotting here.\n",
    "- compute the regression weights using $\\mathbf{X}$ and $\\mathbf{y}$\n",
    "- compute the prediction\n",
    "- compute and print the $R^2$ value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START OF YOUR CODE:\n",
    "\n",
    "# END OF YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>2.4 - Your comments</mark>\n",
    "\n",
    "Did you observe anything interesting with varying values of $d$ ? Comment about it.\n",
    "\n",
    "YOUR COMMENT BELOW:\n",
    "\n",
    "===>\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
